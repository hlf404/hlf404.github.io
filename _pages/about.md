---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>
Hi, I am currently pursuing my PhD in the <a href="http://home.njustkmg.cn:4056/Introduction.html" target="_blank">Knowledge Mining Group (KMG)</a> at the School of Computer Science and Engineering, Nanjing University of Science and Technology. I am supervised by Prof. <a href="http://home.njustkmg.cn:4056/Introduction.html" target="_blank">Yang Yang</a> and Associate Prof. <a href="https://jiangqy.github.io/" target="_blank">Qingyuan Jiang</a>. My research interests focus on multimodal learning.

# üî• News
- *2025.09*: &nbsp; One paper has been accepted by **NeruIPS 2025** as an Oral paper (CCF-A).
- *2025.07*: &nbsp; One paper has been accepted by **ECAI 2025** (CCF-B).
- *2024.09*: &nbsp; One paper has been accepted by **ACML 2024** (CCF-C). 
- *2024.06*: &nbsp; The Second Prize in the 2024 Global AI Technology Innovation Competition - Drone Perspective Dual Light Target Detection.
- *2024.01*: &nbsp; Attended Baidu Wenxin Developer Talk ‚Äî Research and Application of Multimodal Foundation Model Fine-tuning Techniques. 
- *2023.12*: &nbsp; The Champion in the 2023 Global Campus AI Algorithm Elite Competition - Zero-shot Referring Expression Comprehension. 
- *2023.12*: &nbsp; The Second Prize in the 2023 Greater Bay Area (Huangpu) International Algorithm Example Competition - Continual Learning Track.

# üìñ Educations
- *2024.09 - Now*, Postgraduate studies (PhD), Nanjing University of Science and Technology.
- *2023.09 - 2024.09*, Postgraduate studies (Master), Nanjing University of Science and Technology. 
- *2019.09 - 2023.06*, B.E. in Computer Science and Technology, Nanjing Xiaozhuang University.

# üèÜ Honors and Awards
- *2024.04* Outstanding Undergraduate Thesis (Design) Award of Jiangsu Province. 
- *2023.09* Outstanding Undergraduate Thesis (Design) Award of NanJing XiaoZhuang University.

# üìù Publications 

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">NeruIPS 2025</div><img src='images/NIPS25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Rethinking Multimodal Learning from the Perspective of Mitigating Classification Ability Disproportion]

NeruIPS 2025 (Oral) [**Github**]

Qingyuan Jiang, **Longfei Huang**, Yang Yang*

[**Project**]
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ECAI 2025</div><img src='images/ECAI25.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Multimodal Semantic Decoupled Prompt for Zero-Shot Referring Expression Comprehension]

ECAI 2025 [**Github**](https://github.com/hlf404/ECAI25-MSDP)

Yuxuan Zhang<sup>#</sup>, **Longfei Huang**<sup>#</sup>, Yang Yang* (Co-author)

[**Project**]
</div>
</div>

<div class='paper-box'><div class='paper-box-image'><div><div class="badge">ACML 2024</div><img src='images/ACML24.png' alt="sym" width="100%"></div></div>
<div class='paper-box-text' markdown="1">

[Refining Visual Perception for Decoration Display: A Self-Enhanced Deep Captioning Model](https://raw.githubusercontent.com/mlresearch/v260/main/assets/huang25a/huang25a.pdf)

ACML 2024 [**Github**](https://github.com/hlf404/ACML-SET)

**Longfei Huang**, Xiangyu Wu, Jingyuan Wang, Weili Guo, Yang Yang*

[**Project**](https://scholar.google.com/citations?view_op=view_citation&user=eK0HWicAAAAJ&citation_for_view=eK0HWicAAAAJ:2osOgNQ5qMEC) <strong><span class='show_paper_citations' data='eK0HWicAAAAJ:2osOgNQ5qMEC'></span></strong>
</div>
</div>

- [The Solution for the sequential task continual learning track of the 2nd Greater Bay Area International Algorithm Competition](https://scholar.google.com/citations?view_op=view_citation&user=eK0HWicAAAAJ&citation_for_view=eK0HWicAAAAJ:9yKSN-GCB0IC), Competition report.

- [The Solution for the 5th GCAIAC Zero-shot Referring Expression Comprehension Challenge](https://scholar.google.com/citations?view_op=view_citation&user=eK0HWicAAAAJ&citation_for_view=eK0HWicAAAAJ:d1gkVwhDpl0C), Competition report.
  
- [The Solution for the GAIIC2024 RGB-TIR object detection Challenge](https://scholar.google.com/citations?view_op=view_citation&user=eK0HWicAAAAJ&citation_for_view=eK0HWicAAAAJ:u-x6o8ySG0sC), Competition report.
